---
spark_version: "2.0.1-bin-hadoop2.7"
spark_mirror: "http://d3kbcqa49mib13.cloudfront.net"
spark_pkg_name: spark-{{ spark_version }}

spark_src_dir: "/usr/local/src"
spark_conf_dir: "/etc/spark"

spark_usr_parent_dir: "/usr/lib"  #this is the folder where the spark archive will be extracted
spark_usr_dir: "/opt/spark"   #this is the symlink to the extracted/installed spark
spark_lib_dir: "/var/lib/spark"
spark_log_dir: "/var/snap_logs/spark"
spark_run_dir: "/run/spark"
spark_pid_dir: "/var/run/spark"
spark_user: "spark"
spark_group: "spark"
spark_user_shell: "/bin/false"    # the spark user's default shell
spark_default_hadoop_home: "/usr/lib/hadoop"
spark_hdfs_dir: "/user/spark"

spark_env_extras: {}
spark_defaults_extras: {}


spark_driver_memory: 512m

spark_history_dir: "applicationHistory"
spark_history_enabled: true
spark_history_ui_port: 18079

spark_executor_instances: 1
spark_executor_cores: 1

spark_master_webui_port: 18080
spark_master_port: 7077

spark_worker_port: 7078
spark_worker_webui_port: 18081
spark_worker_memory: 2g
spark_worker_dir: "/var/run/spark/work"
spark_worker_instances: 1
spark_worker_cores: 2

spark_stderr_logfile_maxbytes: 50MB
